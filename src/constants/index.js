export const myProjects = [
  {
    id: 1,
    title: "Demcus",
    description:
      "Waveform to waveform model.",
    subDescription: [
      "Developed a waveform-to-waveform model for audio source separation using Wave-U-Net architecture.",
      "Utilized MUSDB HQ dataset for training and evaluation, achieving high-quality audio separation.",
      "Implemented the model in Python with PyTorch, ensuring efficient training and inference.",
      "Contributed to open-source repositories, enhancing accessibility for researchers and developers in the field.",
    ],
    href: "",
    logo: "",
    image: "/assets/projects/demcus.png",
    tags: [
      {
        id: 1,
        name: "python",
        path: "/assets/logos/csharp.svg",
      },
      {
        id: 2,
        name: "Wave-U-Net",
        path: "/assets/logos/dotnet.svg",
      },
      {
        id: 3,
        name: "MUSDB HQ",
        path: "/assets/logos/efcore.png",
      },
      {
        id: 4,
        name: "PyPI",
        path: "/assets/logos/tailwindcss.svg",
      },
    ],
  },
  {
    id: 2,
    title: "ConvTasNet",
    description:
      "Convolution time-domain audio separation model.",
    subDescription: [
      "Developed a convolutional time-domain audio separation model using ConvTasNet architecture.",
      "Utilized MUSDB HQ dataset for training and evaluation, achieving state-of-the-art performance in speech separation tasks.",
      "Implemented the model in Python with PyTorch, ensuring efficient training and inference.",
      "Contributed to open-source repositories, enhancing accessibility for researchers and developers in the field.",
    ],
    href: "",
    logo: "",
    image: "/assets/projects/convtasnet.png",
    tags: [
      {
        id: 1,
        name: "Convolutional",
        path: "/assets/logos/auth0.svg",
      },
      {
        id: 2,
        name: "Speech Separation",
        path: "/assets/logos/react.svg",
      },
      {
        id: 3,
        name: "Time-Domain",
        path: "/assets/logos/sqlite.svg",
      },
      {
        id: 4,
        name: "Python",
        path: "/assets/logos/tailwindcss.svg",
      },
    ],
  },
];

export const mySocials = [
  {
    name: "WhatsApp",
    href: "",
    icon: "/assets/socials/whatsApp.svg",
  },
  {
    name: "Linkedin",
    href: "https://www.linkedin.com/in/ali-sanati/",
    icon: "/assets/socials/linkedIn.svg",
  },
  {
    name: "Instagram",
    href: "https://www.instagram.com/ali.sanatidev/reels/",
    icon: "/assets/socials/instagram.svg",
  },
];

export const experiences = [
  {
    title: "Primary Research",
    job: "Understanding Auditory Attention",
    date: "2021-2022",
    contents: [
      "Research by KU Leuven on auditory attention and mechanisms responsible for neuro-steered attention detection.",
  ],
  },
  {
    title: "Conceptualization",
    job: "Neuro-Steered Headphones",
    date: "2022-2024",
    contents: [
      "Conceptualized a prototype for neuro-steered headphones, integrating auditory attention detection.",
      "Developed a prototype using Raspberry Pi, and EEG sensors to detect auditory attention.",
    ],
  },
  {
    title: "Algorithm Development",
    job: "Auditory Attention Detection",
    date: "2024-Present",
    contents: [
      "Developing algorithms to detect auditory attention using EEG data.",
      "Implementing machine learning techniques to improve accuracy and responsiveness.",
      "Collaborating with researchers to validate and refine the detection algorithms.",
    ],
  },
];
export const reviews = [
  {
    name: "Working Prototype",
    username: "@Studio",
    body: "Prepration to use mBrainTrain Mobile EEG by BRAINBOX.",
    img: "https://brainbox-neuro.com/techniques/mobile-eeg",
  },
  {
    name: "Machine Learning",
    username: "@AI_&_ML",
    body: "Using machine learning on EEG data for auditory scene analysis.",
    img: "https://robohash.org/jill",
  },
  {
    name: "Materials & Equipment",
    username: "@Procurement",
    body: "Procuring best suitable tech for compact user-centric design.",
    img: "https://robohash.org/john",
  },
  {
    name: "Patents & IP",
    username: "@Legal",
    body: "Patenting the neuro-steered plugon design and technology with AR/VR consoles.",
    img: "https://robohash.org/alice",
  },
  {
    name: "Business Development",
    username: "@BizDev",
    body: "Exploring partnerships with tech companies for product integration.",
    img: "https://robohash.org/bob",
  },
  {
    name: "Clinical Trials",
    username: "@Clinical",
    body: "Planning to test the prototype in clinical settings on auditory impared.",
    img: "https://robohash.org/charlie",
  },
  {
    name: "Sensory Enhancement",
    username: "@Feature",
    body: "Checking for enhanced listening sound waves beyond human capabilities.",
    img: "https://robohash.org/dave",
  },
  {
    name: "User Experience",
    username: "@UX_Design",
    body: "Designing user-friendly interfaces for the neuro-steered headphones.",
    img: "https://robohash.org/eve",
  },
];
